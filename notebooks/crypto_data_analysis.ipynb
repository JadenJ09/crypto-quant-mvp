{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4c872d",
   "metadata": {},
   "source": [
    "# Crypto Quantitative Analysis & Historical Data Management\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. **Set up an interactive analysis environment** for crypto time-series data\n",
    "2. **Access current OHLCV data** from our TimescaleDB instance\n",
    "3. **Implement efficient historical data storage** strategies\n",
    "4. **Create time bucketing and continuous aggregations** for fast queries\n",
    "5. **Build scalable data pipelines** for multi-year historical data\n",
    "\n",
    "## üéØ Goals\n",
    "- Understand where our current data is stored and how to access it\n",
    "- Implement best practices for storing 1-minute data from 2025-01-01 to now\n",
    "- Set up TimescaleDB partitioning and continuous aggregations\n",
    "- Create efficient querying patterns for technical analysis and ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf39e82",
   "metadata": {},
   "source": [
    "# 1. Set Up Jupyter Notebook Environment\n",
    "\n",
    "First, let's configure our notebook environment with the necessary settings for optimal crypto data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure notebook environment\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better data visualization\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Configure plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úÖ Notebook environment configured successfully!\")\n",
    "print(\"üìä Pandas display options optimized for time-series data\")\n",
    "print(\"üìà Matplotlib style set to seaborn for better visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335d177",
   "metadata": {},
   "source": [
    "# 2. Import Essential Libraries\n",
    "\n",
    "Import all necessary libraries for data analysis, database connections, visualization, and technical indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "# Database connections\n",
    "import psycopg  # PostgreSQL/TimescaleDB connector\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# Technical analysis\n",
    "try:\n",
    "    import ta  # Technical Analysis library\n",
    "    print(\"‚úÖ Technical Analysis library (ta) available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Installing technical analysis library...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call(['pip', 'install', 'ta'])\n",
    "    import ta\n",
    "\n",
    "# Machine Learning (optional)\n",
    "try:\n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    print(\"‚úÖ Scikit-learn available for ML preprocessing\")\n",
    "except ImportError:\n",
    "    print(\"‚ÑπÔ∏è Scikit-learn not available (install if needed for ML)\")\n",
    "\n",
    "print(\"üìö All essential libraries imported successfully!\")\n",
    "\n",
    "# Database configuration\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5433,\n",
    "    'database': 'quant_db',\n",
    "    'user': 'quant_user',\n",
    "    'password': 'quant_password'\n",
    "}\n",
    "\n",
    "DATABASE_URL = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "print(f\"üîó Database URL configured: {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74504d9",
   "metadata": {},
   "source": [
    "# 3. Load and Inspect Current Data\n",
    "\n",
    "Let's examine what data we currently have in our TimescaleDB instance and understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb27b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_summary():\n",
    "    \"\"\"Get summary of current data in TimescaleDB\"\"\"\n",
    "    try:\n",
    "        with psycopg.connect(DATABASE_URL) as conn:\n",
    "            # Data summary query\n",
    "            summary_query = \"\"\"\n",
    "            SELECT \n",
    "                symbol,\n",
    "                COUNT(*) as total_records,\n",
    "                MIN(time) as earliest_time,\n",
    "                MAX(time) as latest_time,\n",
    "                ROUND(AVG(volume)::numeric, 2) as avg_volume,\n",
    "                ROUND(AVG(close)::numeric, 2) as avg_price,\n",
    "                ROUND((MAX(time) - MIN(time))::numeric / 3600, 2) as hours_of_data\n",
    "            FROM ohlcv_1min \n",
    "            GROUP BY symbol \n",
    "            ORDER BY total_records DESC;\n",
    "            \"\"\"\n",
    "            \n",
    "            df_summary = pd.read_sql_query(summary_query, conn)\n",
    "            \n",
    "            # Overall statistics\n",
    "            total_query = \"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total_records,\n",
    "                COUNT(DISTINCT symbol) as unique_symbols,\n",
    "                MIN(time) as earliest_time,\n",
    "                MAX(time) as latest_time\n",
    "            FROM ohlcv_1min;\n",
    "            \"\"\"\n",
    "            \n",
    "            overall_stats = pd.read_sql_query(total_query, conn)\n",
    "            \n",
    "            return df_summary, overall_stats\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Database connection error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Get current data summary\n",
    "summary_df, overall_stats = get_data_summary()\n",
    "\n",
    "if summary_df is not None:\n",
    "    print(\"üìä CURRENT DATA SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üî¢ Total Records: {overall_stats['total_records'].iloc[0]:,}\")\n",
    "    print(f\"üìà Unique Symbols: {overall_stats['unique_symbols'].iloc[0]}\")\n",
    "    print(f\"‚è∞ Time Range: {overall_stats['earliest_time'].iloc[0]} to {overall_stats['latest_time'].iloc[0]}\")\n",
    "    \n",
    "    duration = overall_stats['latest_time'].iloc[0] - overall_stats['earliest_time'].iloc[0]\n",
    "    hours = duration.total_seconds() / 3600\n",
    "    print(f\"‚è±Ô∏è Total Duration: {hours:.1f} hours\")\n",
    "    \n",
    "    print(\"\\nüìã PER-SYMBOL BREAKDOWN:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"‚ùå Could not connect to database or retrieve data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
